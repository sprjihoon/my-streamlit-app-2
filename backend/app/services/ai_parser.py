"""
AI ê¸°ë°˜ ìž‘ì—…ì¼ì§€ íŒŒì‹± ëª¨ë“ˆ (Function Calling ë°©ì‹)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OpenAI GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ìžì—°ì–´ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
Function Callingì„ í†µí•´ GPTê°€ ì§ì ‘ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
ë©€í‹°í„´ ëŒ€í™”ë¥¼ í†µí•´ ë¶ˆì™„ì „í•œ ì •ë³´ë¥¼ ë³´ì™„í•©ë‹ˆë‹¤.
"""

import os
import json
import unicodedata
from typing import Optional, Dict, Any, List
from datetime import datetime
from dotenv import load_dotenv
from openai import AsyncOpenAI

from backend.app.services.bot_tools import TOOLS, execute_tool, get_db_context_for_ai
from backend.app.services.conversation_state import get_conversation_manager
from logic.db import get_connection

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë‹¨ìˆœí™”ë¨)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë¬¼ë¥˜ì„¼í„° ìž‘ì—…ì¼ì§€ ê´€ë¦¬ ë´‡ìž…ë‹ˆë‹¤.
ì‚¬ìš©ìžì˜ ìžì—°ì–´ ë©”ì‹œì§€ë¥¼ ì´í•´í•˜ê³ , ì ì ˆí•œ ë„êµ¬(function)ë¥¼ í˜¸ì¶œí•˜ê±°ë‚˜ ì§ì ‘ ëŒ€í™”í•©ë‹ˆë‹¤.

## ì˜¤ëŠ˜ ë‚ ì§œ
{today} ({weekday})

{db_context}

## í•µì‹¬ ì—­í• 
1. **ìž‘ì—…ì¼ì§€ ìž…ë ¥**: "í‹¸ë¦¬ì–¸ 1í†¤í•˜ì°¨ 3ë§Œì›" â†’ save_work_log í˜¸ì¶œ
2. **ì¡°íšŒ/ê²€ìƒ‰**: "ì˜¤ëŠ˜ ìž‘ì—… ë³´ì—¬ì¤˜" â†’ search_work_logs í˜¸ì¶œ
3. **í†µê³„**: "ì´ë²ˆë‹¬ ì´ ì–¼ë§ˆ?" â†’ get_work_log_stats í˜¸ì¶œ
4. **ì‚­ì œ**: "ì·¨ì†Œ", "ë°©ê¸ˆê±° ì‚­ì œ" â†’ delete_work_log í˜¸ì¶œ
5. **ìˆ˜ì •**: "ìˆ˜ì •í•´ì¤˜" â†’ update_work_log í˜¸ì¶œ
6. **ë¶ˆì™„ì „ ì •ë³´**: í•„ìˆ˜ ì •ë³´ ëˆ„ë½ ì‹œ â†’ ask_missing_info í˜¸ì¶œ
7. **ì¼ë°˜ ëŒ€í™”**: ë„êµ¬ ì—†ì´ ì§ì ‘ ì‘ë‹µ

## ê¸ˆì•¡ í•´ì„ ê·œì¹™
- ë§Œ = 10000, ì²œ = 1000
- "3ë§Œì›" â†’ 30000
- "ë§Œì›" â†’ 10000
- "5ì²œì›" â†’ 5000

## ë‚ ì§œ í•´ì„ ê·œì¹™
- "ì˜¤ëŠ˜" â†’ {today}
- "ì–´ì œ" â†’ {yesterday}
- "ì´ë²ˆì£¼" â†’ ì´ë²ˆ ì£¼ ì›”ìš”ì¼ ~ ì˜¤ëŠ˜
- "ì§€ë‚œì£¼" â†’ ì§€ë‚œ ì£¼ ì›”ìš”ì¼ ~ ì¼ìš”ì¼
- "ì´ë²ˆë‹¬" â†’ ì´ë²ˆ ë‹¬ 1ì¼ ~ ì˜¤ëŠ˜
- "5ì¼ 6ì¼" â†’ ì´ë²ˆ ë‹¬ 5ì¼ ~ 6ì¼

## ì‘ë‹µ ìŠ¤íƒ€ì¼
- ì¹œê·¼í•˜ê³  ê°„ê²°í•˜ê²Œ
- ì´ëª¨ì§€ ì ì ˆížˆ ì‚¬ìš©
- í•œêµ­ì–´ë¡œ ì‘ë‹µ

## ë¶ˆì™„ì „ ì •ë³´ ì²˜ë¦¬ (ë§¤ìš° ì¤‘ìš”!)
ìž‘ì—…ì¼ì§€ ìž…ë ¥ ì‹œ í•„ìˆ˜ ì •ë³´: **ì—…ì²´ëª…, ìž‘ì—…ì¢…ë¥˜, ë‹¨ê°€**
- "í‹¸ë¦¬ì–¸ í•˜ì°¨" (ë‹¨ê°€ ì—†ìŒ) â†’ ask_missing_info í˜¸ì¶œ (missing: ["unit_price"])
- "3ë§Œì›" (ì—…ì²´/ìž‘ì—… ì—†ìŒ) â†’ ask_missing_info í˜¸ì¶œ (missing: ["vendor", "work_type"])
- "í•˜ì°¨ 3ë§Œì›" (ì—…ì²´ ì—†ìŒ) â†’ ask_missing_info í˜¸ì¶œ (missing: ["vendor"])

âš ï¸ ë¶ˆì™„ì „í•œ ì •ë³´ë¡œ save_work_logë¥¼ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”! ë¨¼ì € ask_missing_infoë¡œ ë¶€ì¡±í•œ ì •ë³´ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”.

## ì´ì „ ëŒ€í™” ë§¥ë½
{pending_context}

## ì¤‘ìš”
- ì‚¬ìš©ìžê°€ ìž‘ì—…ì¼ì§€ í˜•ì‹("ì—…ì²´ëª… ìž‘ì—… ê¸ˆì•¡")ìœ¼ë¡œ ë§í•˜ë©´ save_work_log í˜¸ì¶œ
- ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ask_missing_info í˜¸ì¶œí•˜ì—¬ ë¬¼ì–´ë³´ê¸°
- "ì·¨ì†Œ", "ì‚­ì œ", "ì§€ì›Œì¤˜" ë“±ì€ delete_work_log (delete_recent=true)
- "ìˆ˜ì •", "ê³ ì³ì¤˜", "ë°”ê¿”ì¤˜" ë“±ì€ update_work_log (update_recent=true)
- ë„ì›€ë§/ì‚¬ìš©ë²• ìš”ì²­ì€ get_help í˜¸ì¶œ
- ì¡°íšŒ/ê²€ìƒ‰ì€ search_work_logs ë˜ëŠ” get_work_log_stats
- ì¸ë³´ì´ìŠ¤/ì²­êµ¬ê¸ˆì•¡ ê´€ë ¨ì€ get_invoice_stats í˜¸ì¶œ
- ì¼ë°˜ ëŒ€í™”ë‚˜ ì¸ì‚¬ëŠ” ë„êµ¬ í˜¸ì¶œ ì—†ì´ ì§ì ‘ ì‘ë‹µ

## âš ï¸ ëŒ€í™” ë§¥ë½ ì´í•´ (ë§¤ìš° ì¤‘ìš”!)
- ê¸ˆì•¡ë§Œ ì–¸ê¸‰í•˜ë©´ì„œ "?", "ìž˜ëª»ë", "í‹€ë¦°", "ì´ìƒí•´" ë“±ì´ í¬í•¨ë˜ë©´ â†’ ì´ì „ ë‹µë³€ì— ëŒ€í•œ **ì˜ë¬¸/í”¼ë“œë°±**ìž„
- "3100ë§Œì›? ìž˜ëª»ëœ ê°’ê°™ë„¤" â†’ ìž‘ì—… ìž…ë ¥ì´ ì•„ë‹˜! ì´ì „ ë‹µë³€ì„ ì˜ì‹¬í•˜ëŠ” ê²ƒ
- "ì§„ì§œ?", "ë§žì•„?", "í™•ì‹¤í•´?" â†’ í™•ì¸ ìš”ì²­
- ì´ëŸ° ê²½ìš° ë„êµ¬ í˜¸ì¶œ ì—†ì´ "í™•ì¸í•´ë³¼ê²Œìš”" ë˜ëŠ” ì„¤ëª…ìœ¼ë¡œ ì‘ë‹µ
"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AI íŒŒì„œ í´ëž˜ìŠ¤ (ë‹¨ìˆœí™”ë¨)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AIParser:
    """AI ê¸°ë°˜ ìž‘ì—…ì¼ì§€ íŒŒì„œ (Function Calling + ë©€í‹°í„´ ëŒ€í™” ë°©ì‹)"""
    
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is not set")
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = "gpt-4o-mini"
        
        # ë³„ì¹­ ë§¤í•‘ ìºì‹œ
        self._alias_cache: Optional[Dict[str, str]] = None
        self._alias_cache_time: Optional[datetime] = None
        self._cache_ttl_seconds = 300
        
        # ëŒ€í™” ìƒíƒœ ê´€ë¦¬ìž
        self.conv_manager = get_conversation_manager()
    
    def _get_system_prompt(self, pending_context: str = "") -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        today = datetime.now()
        yesterday = today.replace(day=today.day - 1) if today.day > 1 else today
        weekdays = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        
        if not pending_context:
            pending_context = "(ì´ì „ ëŒ€í™” ë§¥ë½ ì—†ìŒ)"
        
        return SYSTEM_PROMPT.format(
            today=today.strftime("%Y-%m-%d"),
            yesterday=yesterday.strftime("%Y-%m-%d"),
            weekday=weekdays[today.weekday()],
            db_context=get_db_context_for_ai(),
            pending_context=pending_context
        )
    
    def _format_pending_context(self, state: Dict) -> str:
        """ëŒ€ê¸° ì¤‘ì¸ ìƒíƒœë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìžì—´ë¡œ ë³€í™˜"""
        if not state:
            return ""
        
        pending_data = state.get("pending_data", {})
        missing = state.get("missing", [])
        last_question = state.get("last_question", "")
        
        if not pending_data:
            return ""
        
        parts = []
        parts.append("âš ï¸ ì´ì „ ëŒ€í™”ì—ì„œ ë¶ˆì™„ì „í•œ ìž‘ì—…ì¼ì§€ ì •ë³´ê°€ ìžˆìŠµë‹ˆë‹¤:")
        
        if pending_data.get("vendor"):
            parts.append(f"  - ì—…ì²´ëª…: {pending_data['vendor']}")
        if pending_data.get("work_type"):
            parts.append(f"  - ìž‘ì—…ì¢…ë¥˜: {pending_data['work_type']}")
        if pending_data.get("unit_price"):
            parts.append(f"  - ë‹¨ê°€: {pending_data['unit_price']:,}ì›")
        if pending_data.get("qty"):
            parts.append(f"  - ìˆ˜ëŸ‰: {pending_data['qty']}")
        if pending_data.get("date"):
            parts.append(f"  - ë‚ ì§œ: {pending_data['date']}")
        
        if missing:
            field_names = {"vendor": "ì—…ì²´ëª…", "work_type": "ìž‘ì—…ì¢…ë¥˜", "unit_price": "ë‹¨ê°€", "qty": "ìˆ˜ëŸ‰"}
            missing_kr = [field_names.get(m, m) for m in missing]
            parts.append(f"  - ëˆ„ë½ëœ ì •ë³´: {', '.join(missing_kr)}")
        
        if last_question:
            parts.append(f"  - ë§ˆì§€ë§‰ ì§ˆë¬¸: {last_question}")
        
        parts.append("")
        parts.append("ì‚¬ìš©ìžê°€ ëˆ„ë½ëœ ì •ë³´(ì˜ˆ: '3ë§Œì›', 'í‹¸ë¦¬ì–¸')ë¥¼ ì œê³µí•˜ë©´ ê¸°ì¡´ ì •ë³´ì™€ í•©ì³ì„œ complete_pending_entryë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")
        
        return "\n".join(parts)
    
    def _get_alias_map(self) -> Dict[str, str]:
        """ë³„ì¹­ ë§¤í•‘ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)"""
        now = datetime.now()
        
        if (self._alias_cache is None or
            self._alias_cache_time is None or
            (now - self._alias_cache_time).seconds > self._cache_ttl_seconds):
            self._alias_cache = self._load_vendor_aliases()
            self._alias_cache_time = now
        
        return self._alias_cache or {}
    
    def _load_vendor_aliases(self) -> Dict[str, str]:
        """ë³„ì¹­ í…Œì´ë¸”ì—ì„œ ë§¤í•‘ ë¡œë“œ"""
        alias_map = {}
        try:
            with get_connection() as con:
                # aliases í…Œì´ë¸”
                rows = con.execute(
                    "SELECT alias, vendor FROM aliases WHERE file_type = 'work_log'"
                ).fetchall()
                for alias, vendor in rows:
                    if alias and vendor:
                        alias_map[self._normalize(alias)] = vendor
                
                # vendors í…Œì´ë¸”
                vendor_rows = con.execute(
                    "SELECT vendor, name FROM vendors WHERE active != 'NO' OR active IS NULL"
                ).fetchall()
                for vendor, name in vendor_rows:
                    if vendor:
                        alias_map[self._normalize(vendor)] = vendor
                        if name:
                            alias_map[self._normalize(name)] = vendor
        except Exception as e:
            print(f"Warning: Could not load vendor aliases: {e}")
        return alias_map
    
    def _normalize(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        if not text:
            return ""
        normalized = unicodedata.normalize('NFKC', str(text).strip())
        normalized = ' '.join(normalized.split())
        return normalized.lower()
    
    def _map_vendor_alias(self, vendor_name: str) -> str:
        """ìž…ë ¥ëœ ì—…ì²´ëª…ì„ ì‹¤ì œ vendorë¡œ ë³€í™˜"""
        if not vendor_name:
            return vendor_name
        
        alias_map = self._get_alias_map()
        normalized = self._normalize(vendor_name)
        
        # ì •í™•ížˆ ì¼ì¹˜
        if normalized in alias_map:
            return alias_map[normalized]
        
        # ë¶€ë¶„ ì¼ì¹˜
        for alias, vendor in alias_map.items():
            if alias in normalized or normalized in alias:
                return vendor
        
        return vendor_name
    
    async def process_message(
        self,
        message: str,
        user_id: str,
        user_name: str = None,
        channel_id: str = None,
        conversation_history: List[Dict] = None
    ) -> Dict[str, Any]:
        """
        ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ ë°˜í™˜ (Function Calling + ë©€í‹°í„´ ëŒ€í™”)
        
        Args:
            message: ì‚¬ìš©ìž ë©”ì‹œì§€
            user_id: ì‚¬ìš©ìž ID
            user_name: ì‚¬ìš©ìž ì´ë¦„
            channel_id: ì±„ë„ ID
            conversation_history: ì´ì „ ëŒ€í™” ì´ë ¥ (ì„ íƒ)
        
        Returns:
            {
                "response": "ì‚¬ìš©ìžì—ê²Œ ë³´ì—¬ì¤„ ì‘ë‹µ",
                "tool_called": "í˜¸ì¶œëœ ë„êµ¬ ì´ë¦„ ë˜ëŠ” None",
                "tool_result": "ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ë˜ëŠ” None"
            }
        """
        # ëŒ€ê¸° ì¤‘ì¸ ëŒ€í™” ìƒíƒœ í™•ì¸
        pending_state = self.conv_manager.get_state(user_id)
        pending_context = self._format_pending_context(pending_state)
        
        # í™•ìž¥ëœ ë„êµ¬ ëª©ë¡ (ask_missing_info, complete_pending_entry ì¶”ê°€)
        extended_tools = TOOLS + [
            {
                "type": "function",
                "function": {
                    "name": "ask_missing_info",
                    "description": "ìž‘ì—…ì¼ì§€ ì €ìž¥ì— í•„ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•  ë•Œ ì‚¬ìš©ìžì—ê²Œ ë¬¼ì–´ë´…ë‹ˆë‹¤. ë¶€ì¡±í•œ ì •ë³´ë¥¼ ë¬¼ì–´ë³´ë©´ì„œ ì´ë¯¸ íŒŒì•…í•œ ì •ë³´ëŠ” ì €ìž¥í•©ë‹ˆë‹¤.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "vendor": {"type": "string", "description": "íŒŒì•…ëœ ì—…ì²´ëª… (ì—†ìœ¼ë©´ ìƒëžµ)"},
                            "work_type": {"type": "string", "description": "íŒŒì•…ëœ ìž‘ì—…ì¢…ë¥˜ (ì—†ìœ¼ë©´ ìƒëžµ)"},
                            "unit_price": {"type": "integer", "description": "íŒŒì•…ëœ ë‹¨ê°€ (ì—†ìœ¼ë©´ ìƒëžµ)"},
                            "qty": {"type": "integer", "description": "íŒŒì•…ëœ ìˆ˜ëŸ‰ (ì—†ìœ¼ë©´ ìƒëžµ)"},
                            "date": {"type": "string", "description": "íŒŒì•…ëœ ë‚ ì§œ (ì—†ìœ¼ë©´ ìƒëžµ)"},
                            "remark": {"type": "string", "description": "íŒŒì•…ëœ ë¹„ê³  (ì—†ìœ¼ë©´ ìƒëžµ)"},
                            "missing": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "ëˆ„ë½ëœ í•„ë“œ ëª©ë¡ (vendor, work_type, unit_price ì¤‘)"
                            },
                            "question": {"type": "string", "description": "ì‚¬ìš©ìžì—ê²Œ ë¬¼ì–´ë³¼ ì§ˆë¬¸"}
                        },
                        "required": ["missing", "question"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "complete_pending_entry",
                    "description": "ì´ì „ ëŒ€í™”ì—ì„œ ë¶ˆì™„ì „í–ˆë˜ ìž‘ì—…ì¼ì§€ì— ëˆ„ë½ëœ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì—¬ ì™„ì„±í•©ë‹ˆë‹¤.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "vendor": {"type": "string", "description": "ì¶”ê°€ëœ ì—…ì²´ëª…"},
                            "work_type": {"type": "string", "description": "ì¶”ê°€ëœ ìž‘ì—…ì¢…ë¥˜"},
                            "unit_price": {"type": "integer", "description": "ì¶”ê°€ëœ ë‹¨ê°€"},
                            "qty": {"type": "integer", "description": "ì¶”ê°€ëœ ìˆ˜ëŸ‰"},
                            "date": {"type": "string", "description": "ì¶”ê°€ëœ ë‚ ì§œ"},
                            "remark": {"type": "string", "description": "ì¶”ê°€ëœ ë¹„ê³ "}
                        }
                    }
                }
            }
        ]
        
        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            {"role": "system", "content": self._get_system_prompt(pending_context)}
        ]
        
        # ëŒ€í™” ì´ë ¥ ì¶”ê°€ (ìžˆìœ¼ë©´)
        if conversation_history:
            messages.extend(conversation_history[-6:])
        
        # ì‚¬ìš©ìž ë©”ì‹œì§€ ì¶”ê°€
        user_msg = message
        if user_name:
            user_msg = f"[{user_name}] {message}"
        messages.append({"role": "user", "content": user_msg})
        
        try:
            # GPT í˜¸ì¶œ (Function Calling í¬í•¨)
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=extended_tools,
                tool_choice="auto",
                temperature=0.3
            )
            
            assistant_message = response.choices[0].message
            
            # ë„êµ¬ í˜¸ì¶œì´ ìžˆëŠ” ê²½ìš°
            if assistant_message.tool_calls:
                tool_call = assistant_message.tool_calls[0]
                tool_name = tool_call.function.name
                tool_args = json.loads(tool_call.function.arguments)
                
                # ì—…ì²´ëª… ë³„ì¹­ ë§¤í•‘ ì ìš©
                if "vendor" in tool_args:
                    tool_args["vendor"] = self._map_vendor_alias(tool_args["vendor"])
                
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                # íŠ¹ìˆ˜ ë„êµ¬ ì²˜ë¦¬: ask_missing_info
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                if tool_name == "ask_missing_info":
                    # ë¶ˆì™„ì „í•œ ì •ë³´ ì €ìž¥
                    pending_data = {
                        k: v for k, v in tool_args.items()
                        if k in ["vendor", "work_type", "unit_price", "qty", "date", "remark"] and v
                    }
                    missing = tool_args.get("missing", [])
                    question = tool_args.get("question", "ì¶”ê°€ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.")
                    
                    self.conv_manager.set_state(
                        user_id=user_id,
                        channel_id=channel_id or "",
                        pending_data=pending_data,
                        missing=missing,
                        last_question=question
                    )
                    
                    return {
                        "response": f"â“ {question}",
                        "tool_called": tool_name,
                        "tool_result": {"pending_data": pending_data, "missing": missing},
                        "waiting_for_info": True
                    }
                
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                # íŠ¹ìˆ˜ ë„êµ¬ ì²˜ë¦¬: complete_pending_entry
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                if tool_name == "complete_pending_entry":
                    if not pending_state:
                        return {
                            "response": "ðŸ¤” ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì²˜ìŒë¶€í„° ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.",
                            "tool_called": tool_name,
                            "tool_result": None
                        }
                    
                    # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° ë³‘í•©
                    merged_data = pending_state.get("pending_data", {}).copy()
                    for key, value in tool_args.items():
                        if value:
                            if key == "vendor":
                                value = self._map_vendor_alias(value)
                            merged_data[key] = value
                    
                    # ëŒ€í™” ìƒíƒœ í´ë¦¬ì–´
                    self.conv_manager.clear_state(user_id)
                    
                    # í•„ìˆ˜ í•„ë“œ í™•ì¸
                    required = ["vendor", "work_type", "unit_price"]
                    still_missing = [f for f in required if not merged_data.get(f)]
                    
                    if still_missing:
                        field_names = {"vendor": "ì—…ì²´ëª…", "work_type": "ìž‘ì—…ì¢…ë¥˜", "unit_price": "ë‹¨ê°€"}
                        missing_kr = [field_names[f] for f in still_missing]
                        return {
                            "response": f"â“ ì•„ì§ {', '.join(missing_kr)}ì´(ê°€) í•„ìš”í•´ìš”.",
                            "tool_called": tool_name,
                            "tool_result": {"merged_data": merged_data, "still_missing": still_missing}
                        }
                    
                    # save_work_log ì‹¤í–‰
                    tool_result = execute_tool("save_work_log", merged_data, user_id, user_name)
                    
                    if tool_result.get("success"):
                        return {
                            "response": f"âœ… {tool_result.get('message', 'ì €ìž¥ì™„ë£Œ!')}",
                            "tool_called": "save_work_log",
                            "tool_result": tool_result
                        }
                    else:
                        return {
                            "response": f"âŒ ì €ìž¥ ì‹¤íŒ¨: {tool_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}",
                            "tool_called": "save_work_log",
                            "tool_result": tool_result
                        }
                
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                # ì¼ë°˜ ë„êµ¬ ì²˜ë¦¬
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                
                # ì €ìž¥ ì„±ê³µ ì‹œ ëŒ€í™” ìƒíƒœ í´ë¦¬ì–´
                if tool_name == "save_work_log":
                    self.conv_manager.clear_state(user_id)
                
                # ë„êµ¬ ì‹¤í–‰
                tool_result = execute_tool(tool_name, tool_args, user_id, user_name)
                
                # ë„êµ¬ ê²°ê³¼ë¥¼ GPTì—ê²Œ ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±
                # assistant_messageë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (Pydantic ì§ë ¬í™” ì˜¤ë¥˜ ë°©ì§€)
                assistant_msg_dict = {
                    "role": "assistant",
                    "content": assistant_message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        }
                        for tc in assistant_message.tool_calls
                    ] if assistant_message.tool_calls else None
                }
                messages.append(assistant_msg_dict)
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": json.dumps(tool_result, ensure_ascii=False)
                })
                
                # ìµœì¢… ì‘ë‹µ ìƒì„±
                final_response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.5
                )
                
                return {
                    "response": final_response.choices[0].message.content,
                    "tool_called": tool_name,
                    "tool_result": tool_result
                }
            
            # ë„êµ¬ í˜¸ì¶œ ì—†ì´ ì§ì ‘ ì‘ë‹µ
            return {
                "response": assistant_message.content,
                "tool_called": None,
                "tool_result": None
            }
        
        except Exception as e:
            return {
                "response": f"ðŸ¤– ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "tool_called": None,
                "tool_result": None,
                "error": str(e)
            }
    
    async def process_with_confirmation(
        self,
        message: str,
        user_id: str,
        user_name: str = None,
        pending_action: Dict = None
    ) -> Dict[str, Any]:
        """
        í™•ì¸ì´ í•„ìš”í•œ ìž‘ì—… ì²˜ë¦¬ (ì‚­ì œ í™•ì¸ ë“±)
        
        Args:
            message: ì‚¬ìš©ìž ë©”ì‹œì§€
            user_id: ì‚¬ìš©ìž ID
            user_name: ì‚¬ìš©ìž ì´ë¦„
            pending_action: ëŒ€ê¸° ì¤‘ì¸ ìž‘ì—… ì •ë³´
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        if not pending_action:
            return await self.process_message(message, user_id, user_name)
        
        # í™•ì¸ ì‘ë‹µ í•´ì„
        message_lower = message.strip().lower()
        positive = ["ì˜ˆ", "ë„¤", "ì‘", "ë§žì•„", "ê·¸ëž˜", "ã…‡ã…‡", "ã…‡", "yes", "ok", "í™•ì¸", "í•´ì¤˜", "ì €ìž¥", "ì‚­ì œí•´"]
        negative = ["ì•„ë‹ˆ", "ì•„ë‡¨", "ì·¨ì†Œ", "ã„´ã„´", "ì•ˆí•´", "ê·¸ë§Œ", "no", "ì‹«ì–´"]
        
        is_yes = any(p in message_lower for p in positive)
        is_no = any(n in message_lower for n in negative)
        
        if is_yes:
            # ëŒ€ê¸° ì¤‘ì¸ ìž‘ì—… ì‹¤í–‰
            action = pending_action.get("action")
            args = pending_action.get("args", {})
            
            tool_result = execute_tool(action, args, user_id, user_name)
            
            if tool_result.get("success"):
                return {
                    "response": f"âœ… {tool_result.get('message', 'ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')}",
                    "tool_called": action,
                    "tool_result": tool_result,
                    "confirmed": True
                }
            else:
                return {
                    "response": f"âŒ {tool_result.get('error', 'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')}",
                    "tool_called": action,
                    "tool_result": tool_result,
                    "confirmed": True
                }
        
        elif is_no:
            return {
                "response": "ðŸš« ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "tool_called": None,
                "tool_result": None,
                "confirmed": False,
                "cancelled": True
            }
        
        # í™•ì¸/ì·¨ì†Œê°€ ì•„ë‹Œ ê²½ìš° ì¼ë°˜ ì²˜ë¦¬
        return await self.process_message(message, user_id, user_name)
    
    async def chat_response(
        self,
        message: str,
        user_name: str = None
    ) -> str:
        """
        ì¼ë°˜ ëŒ€í™” ì‘ë‹µ ìƒì„± (ë„êµ¬ ì—†ì´)
        
        Args:
            message: ì‚¬ìš©ìž ë©”ì‹œì§€
            user_name: ì‚¬ìš©ìž ì´ë¦„
        
        Returns:
            ì‘ë‹µ ë©”ì‹œì§€
        """
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": f"[{user_name or 'ì‚¬ìš©ìž'}] {message}"}
                ],
                temperature=0.7,
                max_tokens=500
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"ðŸ¤– ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_parser: Optional[AIParser] = None


def get_ai_parser() -> AIParser:
    """AI íŒŒì„œ ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _parser
    if _parser is None:
        _parser = AIParser()
    return _parser
